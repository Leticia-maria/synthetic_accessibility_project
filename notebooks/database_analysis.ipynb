{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Analysis Code\n",
    "\n",
    "Contains code to analyse the training set dataset used for the MPScore. This includes: identifying the functional groups present in the training database; an analysis of the consistency between chemists and the correlation between the SAScore, SCScore and chemist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from rdkit.Chem import AllChem as rdkit\n",
    "import csv\n",
    "from rdkit.Chem.MolStandardize import standardize_smiles\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as it\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the functional groups in the training dataset\n",
    "def find_functional_groups():\n",
    "    training_db = \"data/training_mols.json\"\n",
    "    with open(training_db, \"r\") as f:\n",
    "        training_db = json.load(f)\n",
    "    fg_smarts = {\n",
    "        'amine': ('[N]([H])[H]'),\n",
    "        'aldehyde': ('[C](=[O])[H]'),\n",
    "        'carboxylic_acid': ('[C](=[O])-[O][H]'),\n",
    "        'fluorine': ('[F]'),\n",
    "        'chlorine': ('[Cl]'),\n",
    "        'bromine': ('[Br]'),\n",
    "        'iodine': ('[I]'),\n",
    "        'astatine': ('[As]'),\n",
    "        'alcohol': ('[C]([H])([H])-[O][H]'),\n",
    "        'alcohol2': ('[O][H]'),\n",
    "        'alkene': ('[C]=[C]([H])[H]'),\n",
    "        'alkyne': ('[C]#[C][H]'),\n",
    "        'thiol': ('[S][H]'),\n",
    "        'amide': ('[C](=[O])[N]([H])[H]'),\n",
    "        'boronic_acid': ('[B]([O][H])[O][H]'),\n",
    "        'xenon': ('[Xe]'),\n",
    "        'methyl': ('[C]([H])([H])[H]'),\n",
    "        'ethyl': ('[C]([H])([H])[C]([H])([H])[H]'),\n",
    "        'propyl': ('[C]([H])([H])[C]([H])([H])[C]([H])([H])[H]'),\n",
    "    }\n",
    "    fg_counter = defaultdict(int)\n",
    "    removed = []\n",
    "    for inchi in tqdm(training_db):\n",
    "        mol = Chem.AddHs(Chem.MolFromInchi(inchi))\n",
    "        for fg in fg_smarts:\n",
    "            fg_smart = fg_smarts[fg]\n",
    "            counter = 0\n",
    "            substruct = Chem.MolFromSmarts(fg_smart)\n",
    "            matches = mol.GetSubstructMatches(substruct)\n",
    "            counter += len(matches)\n",
    "            # Ignore molecules if functional groups are less than two.\n",
    "            if counter >= 2:\n",
    "                fg_counter[f'{fg}_{counter}'] += 1\n",
    "                removed.append(inchi)\n",
    "                break\n",
    "    sorted_db_funcs = sorted(fg_counter.items(), key=lambda x: x[0])\n",
    "    db_funcs = pd.DataFrame(sorted_db_funcs)\n",
    "    return db_funcs\n",
    "db_fgs = find_functional_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing chemist scores\n",
    "def load_chemist_data():\n",
    "    p1 = main_dir.joinpath(\"data/chemist_data/opinions_becky.json\")\n",
    "    p2 = main_dir.joinpath(\"data/chemist_data/opinions_mebriggs.json\")\n",
    "    p3 = main_dir.joinpath(\"data/chemist_data/filip.csv\")\n",
    "    # Finding disagreements in training data\n",
    "    with open(str(p1)) as f:\n",
    "        rg = json.load(f)\n",
    "    with open(str(p2)) as f:\n",
    "        mb = json.load(f)\n",
    "    with open(str(p3)) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        fs = {rdkit.MolToInchi(rdkit.MolFromSmiles(smi)): sco for sco, smi in reader}\n",
    "    def parse_training(training_dict):\n",
    "        d = defaultdict(list)\n",
    "        for inchi in training_dict:\n",
    "            # Convert and standardise SMILES string.\n",
    "            d['smiles'].append(standardize_smiles(rdkit.MolToSmiles(rdkit.MolFromInchi(inchi))))\n",
    "            d['chemist_score'].append(int(training_dict[inchi]))\n",
    "        return pd.DataFrame(d)\n",
    "    fs = parse_training(fs)\n",
    "    rg = parse_training(rg)\n",
    "    mb = parse_training(mb)\n",
    "    # Molecules scored by all three chemists\n",
    "    all_three = rg.rename(columns={'chemist_score': 'RLG'}).merge(fs.rename(columns={'chemist_score': 'FS'}), on='smiles').merge(mb.rename(columns={'chemist_score': 'MB'}), on='smiles')\n",
    "    # Molecules scored by two chemists\n",
    "    two = pd.concat([rg.merge(fs, on='smiles'), fs.merge(mb, on='smiles'), rg.merge(mb, on='smiles')])\n",
    "    mols = [] \n",
    "    rows = []\n",
    "    count = 0\n",
    "    for i, r in all_three.iterrows():\n",
    "        if (int(r.RLG) != int(r.FS)) or (int(r.FS) != int(r.MB)):\n",
    "            count+=1\n",
    "            rows.append(r)\n",
    "            mols.append(r.smiles)\n",
    "    print(f\"There were {len(all_three)} molecules labelled by all three chemists\")\n",
    "    print(f\"{count} molecules were labelled the same by all three chemists and {len(all_three)-count} were labelled differently.\")\n",
    "    count = 0\n",
    "    column_names = ['RLG', 'FS', 'MB']\n",
    "    df1 = rg.merge(fs, on='smiles')\n",
    "    df1[~df1['smiles'].isin(all_three['smiles'])]\n",
    "    df2 = rg.merge(mb, on='smiles')\n",
    "    df2[~df2['smiles'].isin(all_three['smiles'])]\n",
    "    df3 = fs.merge(mb, on='smiles')\n",
    "    df3[~df3['smiles'].isin(all_three['smiles'])]\n",
    "    for r in pd.concat([df1, df2, df3]).itertuples():\n",
    "        if (int(r.chemist_score_x) == int(r.chemist_score_y)):\n",
    "            count+=1\n",
    "    print(f'There were {count} molecules labelled the same out of those scored by two chemists.')\n",
    "    print(f'There were {len(pd.concat([df1, df2, df3])) - count} molecules labelled differently out of those scored by two chemists.')\n",
    "    print(f'RLG labelled {sum(rg.chemist_score)} easy-to-synthesise and {len(rg)-sum(rg.chemist_score)} difficult-to-synthesise')\n",
    "    print(f'FS labelled {sum(fs.chemist_score)} easy-to-synthesise and {len(fs)-sum(fs.chemist_score)} difficult-to-synthesise')\n",
    "    print(f'MB labelled {sum(mb.chemist_score)} easy-to-synthesise and {len(mb)-sum(mb.chemist_score)} difficult-to-synthesise')\n",
    "    return \n",
    "data = load_chemist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between the SAScore and SCScore\n",
    "def plot_figure4():\n",
    "    df_training = pd.read_csv(main_dir.joinpath('data/chemist_data/training_data_with_sascores.csv'), names=['smiles', 'sas', 'scs', 'chemist_score', 'sas_norm', 'scs_norm'])\n",
    "    # Scaling scores between 0 and 1\n",
    "    df_training['sas_norm'] = [(val-10)/(1-10) for val in df_training['sas'].to_list()]\n",
    "    df_training['scs_norm'] = [(val-5)/(1-5) for val in df_training['scs'].to_list()]\n",
    "    # Plotting SA-SCScore correlations.\n",
    "    print(f\"The correlation between the SAScore and SCScore is: {df_training['scs'].corr(df_training['sas'])}\")\n",
    "    sns.set_style('white')\n",
    "    palette = sns.color_palette() \n",
    "    # Green = palette[2] = Easy-to-synthesise\n",
    "    # Red = palette[3] = Difficult-to-synthesise \n",
    "    colors = [palette[3]] + [palette[2]]\n",
    "    g = sns.jointplot(\n",
    "        data=df_training,\n",
    "        x='sas_norm',\n",
    "        y='scs_norm',\n",
    "        hue='chemist_score',\n",
    "        palette=colors,\n",
    "        space=0.3,\n",
    "        xlim=[0,1.1],\n",
    "        ylim=[0,1.1],\n",
    "        s=5,\n",
    "        linewidth=0.2,\n",
    "        height= 3.3\n",
    "    )\n",
    "    g.set_axis_labels(xlabel='SAScore', ylabel='SCScore', fontsize='medium')\n",
    "    g.ax_joint.legend_.remove()\n",
    "    g.ax_joint.tick_params('both', labelsize='medium')\n",
    "    return g\n",
    "plot_figure4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Precursor Screening\n",
    "\n",
    "In this section, we filter for easy-to-synthesise molecules using our developed MPScore, the SAScore and SCScore.\n",
    "We show the distriubtions of synthetic difficulty scores for each precursor combination in our precursor database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure6():\n",
    "    # Loading Reaxys data\n",
    "    import sys\n",
    "    sys.path.append(str(main_dir))\n",
    "    from scripts.mpscore import MPScore\n",
    "    con = create_engine(\n",
    "        f\"sqlite:///{str(main_dir.joinpath('data/reaxys_precursors.db'))}\"\n",
    "    )\n",
    "    df_reaxys = pd.read_sql(sql=\"synthetic_accesibility\", con=con)\n",
    "    # Perform standardization on all molecules in Reaxys.\n",
    "    model = MPScore()\n",
    "    model.restore()\n",
    "    df_reaxys['standardized_smiles'] = [standardize_smiles(smi) for smi in df_reaxys['smiles']]\n",
    "    df_reaxys['rfmodel_fulldataset'] = [model.predict_proba(rdkit.AddHs(rdkit.MolFromSmiles(x))) for x in tqdm(df_reaxys['standardized_smiles'])]\n",
    "    bb_gen = it.product(\n",
    "        (r[1] for r in df_reaxys[df_reaxys[\"func_group\"] == \"primary amine\"].iterrows()),\n",
    "        (r[1] for r in df_reaxys[df_reaxys[\"func_group\"] == \"aldehyde\"].iterrows()),\n",
    "    )\n",
    "    combinations = defaultdict(list)\n",
    "    smiles_cache = {}\n",
    "    for bbs in tqdm(bb_gen):\n",
    "        _bb = smiles_cache.get(bbs[0]['smiles'], None)\n",
    "        amine_smiles =  _bb if _bb else standardize_smiles(bbs[0]['smiles'])\n",
    "        _bb = amine_smiles\n",
    "        smiles_cache[bbs[0]['smiles']] = _bb\n",
    "        _bb = smiles_cache.get(bbs[1]['smiles'], None)\n",
    "        aldehyde_smiles =  _bb if _bb else standardize_smiles(bbs[1]['smiles'])\n",
    "        _bb = aldehyde_smiles\n",
    "        smiles_cache[bbs[1]['smiles']] = _bb\n",
    "        combinations[\"bb\"].append(\n",
    "            aldehyde_smiles + ',' + amine_smiles\n",
    "        )\n",
    "        combinations[\"sascore_combination\"].append(sum(r[\"sascore\"] for r in bbs)/2)\n",
    "        combinations[\"scscore_combination\"].append(sum(r[\"scscore\"] for r in bbs)/2)\n",
    "        combinations[\"rfmodel_fulldataset_combination\"].append(sum(r[\"rfmodel_fulldataset\"] for r in bbs)/2)\n",
    "    df_combinations = pd.DataFrame(combinations)\n",
    "    sns.set_style('white')\n",
    "    palette = sns.color_palette()\n",
    "    fig, ax = plt.subplots(1, figsize=(6.43420506434205/2, 3.1))\n",
    "    sns.kdeplot(data=df_combinations, x='sascore_combination', ax=ax, color=palette[0])\n",
    "    sns.kdeplot(data=df_combinations, x='scscore_combination', ax=ax, color=palette[1])\n",
    "    sns.kdeplot(data=df_combinations, x='rfmodel_fulldataset_combination', ax=ax, color=palette[3])\n",
    "    sns.despine()\n",
    "    ax.set_xlabel('Synthetic Difficulty', fontsize='medium')\n",
    "    ax.set_ylabel('Density', fontsize='medium')\n",
    "    ax.axvline(df_combinations['sascore_combination'].quantile(0.01), 0, 0.7, color=palette[0], linestyle =\"--\")\n",
    "    ax.text(df_combinations['sascore_combination'].quantile(0.01)+0.033, 3.7, f\"{round(df_combinations['sascore_combination'].quantile(0.01), 2)}\", color=palette[0], fontsize=8)\n",
    "    ax.text(df_combinations['sascore_combination'].quantile(0.01)+0.03, 4, \"SAScore\", color=palette[0], fontsize=8)\n",
    "\n",
    "    # ax.arrow(df_combinations['sascore_combination'].quantile(0.01), 4.45, -df_combinations['sascore_combination'].quantile(0.01), 0, color=palette[0], shape='full', head_width=0.25, head_length=0.03, length_includes_head=True)\n",
    "    ax.axvline(df_combinations['scscore_combination'].quantile(0.01), 0, 0.7, color=palette[1], linestyle =\"--\")\n",
    "    ax.text(df_combinations['scscore_combination'].quantile(0.01)-0.05, 3.7, f\"{round(df_combinations['scscore_combination'].quantile(0.01), 2)}\", color=palette[1], fontsize=8)\n",
    "    ax.text(df_combinations['scscore_combination'].quantile(0.01)-0.07, 4, \"SCScore\", color=palette[1], fontsize=8)\n",
    "\n",
    "    # ax.arrow(1, 4.75, -df_combinations['scscore_combination'].quantile(0.01), 0, color=palette[1], shape='full', head_width=0.25, head_length=0.03, length_includes_head=True)\n",
    "    ax.axvline(df_combinations['rfmodel_fulldataset_combination'].quantile(0.01), 0, 0.7, color=palette[3], linestyle =\"--\")\n",
    "    ax.text(df_combinations['rfmodel_fulldataset_combination'].quantile(0.01)-0.05, 3.7, f\"{round(df_combinations['rfmodel_fulldataset_combination'].quantile(0.01), 2)}\", color=palette[3], fontsize=8)\n",
    "    ax.text(df_combinations['rfmodel_fulldataset_combination'].quantile(0.01)-0.11, 4, \"MPScore\", color=palette[3], fontsize=8)\n",
    "    ax.tick_params(labelsize='medium')\n",
    "    # ax.arrow(df_combinations['rfmodel_fulldataset_combination'].quantile(0.01), 4.15, -df_combinations['rfmodel_fulldataset_combination'].quantile(0.01), 0, color=palette[3], shape='full', head_width=0.25, head_length=0.03, length_includes_head=True)\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    return fig, ax\n",
    "df_combinations = plot_figure6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precursor_combinations():\n",
    "    # Loading Reaxys data\n",
    "    import sys\n",
    "    sys.path.append(str(main_dir))\n",
    "    from scripts.mpscore import MPScore\n",
    "    con = create_engine(\n",
    "        f\"sqlite:///{str(main_dir.joinpath('data/reaxys_precursors.db'))}\"\n",
    "    )\n",
    "    df_reaxys = pd.read_sql(sql=\"synthetic_accesibility\", con=con)\n",
    "    # Perform standardization on all molecules in Reaxys.\n",
    "    model = MPScore()\n",
    "    model.restore('models/mpscore.joblib')\n",
    "    df_reaxys['standardized_smiles'] = [standardize_smiles(smi) for smi in df_reaxys['smiles']]\n",
    "    df_reaxys['rfmodel_fulldataset'] = [model.predict_proba(rdkit.AddHs(rdkit.MolFromSmiles(x))) for x in tqdm(df_reaxys['standardized_smiles'])]\n",
    "    bb_gen = it.product(\n",
    "        (r[1] for r in df_reaxys[df_reaxys[\"func_group\"] == \"primary amine\"].iterrows()),\n",
    "        (r[1] for r in df_reaxys[df_reaxys[\"func_group\"] == \"aldehyde\"].iterrows()),\n",
    "    )\n",
    "    combinations = defaultdict(list)\n",
    "    smiles_cache = {}\n",
    "    for bbs in tqdm(bb_gen):\n",
    "        _bb = smiles_cache.get(bbs[0]['smiles'], None)\n",
    "        amine_smiles =  _bb if _bb else standardize_smiles(bbs[0]['smiles'])\n",
    "        _bb = amine_smiles\n",
    "        smiles_cache[bbs[0]['smiles']] = _bb\n",
    "        _bb = smiles_cache.get(bbs[1]['smiles'], None)\n",
    "        aldehyde_smiles =  _bb if _bb else standardize_smiles(bbs[1]['smiles'])\n",
    "        _bb = aldehyde_smiles\n",
    "        smiles_cache[bbs[1]['smiles']] = _bb\n",
    "        combinations[\"bb\"].append(\n",
    "            aldehyde_smiles + ',' + amine_smiles\n",
    "        )\n",
    "        combinations[\"sascore_combination\"].append(sum(r[\"sascore\"] for r in bbs)/2)\n",
    "        combinations[\"scscore_combination\"].append(sum(r[\"scscore\"] for r in bbs)/2)\n",
    "        combinations[\"rfmodel_fulldataset_combination\"].append(sum(r[\"rfmodel_fulldataset\"] for r in bbs)/2)\n",
    "    return pd.DataFrame(combinations)\n",
    "df_combinations = get_precursor_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_7():\n",
    "    # Loading optimised cages\n",
    "    df = pd.read_json('cages.json').drop_duplicates('bb')\n",
    "    df_random_selection = pd.read_json('control_cages.json')\n",
    "    df_random_selection = df_random_selection.rename(columns={'_id':'bb'})\n",
    "    # Selecting first percentile of synthetic accessibility scores for the MPScore.\n",
    "    ecm_selected_full = df_combinations[df_combinations['rfmodel_fulldataset_combination'] < df_combinations['rfmodel_fulldataset_combination'].quantile(0.01)].drop_duplicates('bb')\n",
    "    sa_selected = df_combinations[df_combinations['sascore_combination'] < df_combinations['sascore_combination'].quantile(0.01)].drop_duplicates('bb')\n",
    "    sc_selected = df_combinations[df_combinations['scscore_combination'] < df_combinations['scscore_combination'].quantile(0.01)].drop_duplicates('bb')\n",
    "    ecm_cages = ecm_selected_full[ecm_selected_full['bb'].isin(df['bb'])]\n",
    "    ecm_cages = pd.merge(ecm_cages, df, left_on='bb', right_on='bb')\n",
    "    sa_cages = sa_selected[sa_selected['bb'].isin(df['bb'])]\n",
    "    sa_cages = pd.merge(sa_cages, df, left_on='bb', right_on='bb')\n",
    "    sc_cages = sc_selected[sc_selected['bb'].isin(df['bb'])]\n",
    "    sc_cages = pd.merge(sc_cages, df, left_on='bb', right_on='bb')\n",
    "    sp_sc_cages = sc_cages[(sc_cages['collapsed'] == False) & (sc_cages['cavity_size'] > 1.0)].drop_duplicates('bb')\n",
    "    sp_ecm_cages = ecm_cages[(ecm_cages['collapsed'] == False) & (ecm_cages['cavity_size'] > 1.0)].drop_duplicates('bb')\n",
    "    sp_sa_cages = sa_cages[(sa_cages['collapsed'] == False) & (sa_cages['cavity_size'] > 1.0)].drop_duplicates('bb')\n",
    "    sp_random = df_random_selection[(df_random_selection['collapsed'] == False) &  (df_random_selection['cavity_size'] > 1.0)].drop_duplicates('bb')\n",
    "    print(f\"Mean of SCScore selected cages: {sp_sc_cages['cavity_size'].mean()}\")\n",
    "    print(f\"Mean of SAScore selected cages: {sp_sa_cages['cavity_size'].mean()}\")\n",
    "    print(f\"Mean of MPScore selected cages: {sp_ecm_cages['cavity_size'].mean()}\")\n",
    "    print(f\"Mean of randomly selected cages: {sp_random['cavity_size'].mean()}\")\n",
    "    print(\n",
    "        f\"Number of shape persistent from SCScore: {len(sp_sc_cages)}\\n\"\n",
    "        f\"Number of shape persistent from SAScore: {len(sp_sa_cages)}\\n\"\n",
    "        f\"Number of shape persistent from MPScore: {len(sp_ecm_cages)}\\n\"\n",
    "        f\"Number of shape persistent from control sample: {len(sp_random)}\\n\"\n",
    "    )\n",
    "    palette = sns.color_palette()\n",
    "    colors = {\n",
    "        'sascore': palette[0],\n",
    "        'scscore': palette[1],\n",
    "        'ecm': palette[3]\n",
    "    }\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(6.43420506434205/2, 3.3))\n",
    "    ecm_cavity_sizes = sp_ecm_cages['cavity_size']\n",
    "    sns.histplot(x=ecm_cavity_sizes, ax=ax, kde=False, color=colors['ecm'], element='step', edgecolor=colors['ecm'], linewidth=1, alpha=0.4, label='MPScore')\n",
    "    sa_cavity_sizes =sp_sa_cages['cavity_size']\n",
    "    sns.histplot(x=sa_cavity_sizes, ax=ax , kde=False, color=colors['sascore'], element='step', edgecolor=colors['sascore'], linewidth=1, alpha=0.4, label='SAScore')\n",
    "    random_cavity_sizes = df_random_selection[(df_random_selection['collapsed'] == False) &  (df_random_selection['cavity_size'] > 1.0)]['cavity_size']\n",
    "    sns.histplot(x=random_cavity_sizes, ax=ax, kde=False, color='green', element='step', edgecolor='green', linewidth=1, alpha=0.4, label='Control Sample')\n",
    "    sc_cavity_sizes = sp_sc_cages['cavity_size']\n",
    "    sns.histplot(x=sc_cavity_sizes, ax=ax, kde=False, color=colors['scscore'], element='step', edgecolor=colors['scscore'], linewidth=1, alpha=0.4, label='SCScore')\n",
    "    ax.set_xlim(0, 25)\n",
    "    ax.set_xlabel('Cavity Diameter / Å', fontsize='medium')\n",
    "    ax.set_ylabel('Number of Cages', fontsize='medium')\n",
    "    sns.despine()\n",
    "    ax.tick_params(labelsize='medium')\n",
    "    ax.legend()\n",
    "    return fig\n",
    "plot_figure_7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_cages():\n",
    "    df = pd.read_json('cages.json').drop_duplicates('bb')\n",
    "    ecm_selected_full = df_combinations[df_combinations['rfmodel_fulldataset_combination'] < df_combinations['rfmodel_fulldataset_combination'].quantile(0.01)].drop_duplicates('bb')\n",
    "    sa_selected = df_combinations[df_combinations['sascore_combination'] < df_combinations['sascore_combination'].quantile(0.01)].drop_duplicates('bb')\n",
    "    sc_selected = df_combinations[df_combinations['scscore_combination'] < df_combinations['scscore_combination'].quantile(0.01)].drop_duplicates('bb')\n",
    "    ecm_cages = ecm_selected_full[ecm_selected_full['bb'].isin(df['bb'])]\n",
    "    ecm_cages = pd.merge(ecm_cages, df, left_on='bb', right_on='bb')\n",
    "    sa_cages = sa_selected[sa_selected['bb'].isin(df['bb'])]\n",
    "    sa_cages = pd.merge(sa_cages, df, left_on='bb', right_on='bb')\n",
    "    sc_cages = sc_selected[sc_selected['bb'].isin(df['bb'])]\n",
    "    sc_cages = pd.merge(sc_cages, df, left_on='bb', right_on='bb')\n",
    "    sp_sc_cages = sc_cages[(sc_cages['collapsed'] == False) & (sc_cages['cavity_size'] > 1.0)]\n",
    "    sp_ecm_cages = ecm_cages[(ecm_cages['collapsed'] == False) & (ecm_cages['cavity_size'] > 1.0)]\n",
    "    sp_sa_cages = sa_cages[(sa_cages['collapsed'] == False) & (sa_cages['cavity_size'] > 1.0)]\n",
    "    sp_random = df_random_selection[(df_random_selection['collapsed'] == False) &  (df_random_selection['cavity_size'] > 1.0)]\n",
    "    largest_cages = pd.concat([sp_sc_cages, sp_sa_cages, sp_ecm_cages])\n",
    "    largest_cages = largest_cages.query('cavity_size > 16.0')\n",
    "    # Used to replace SMILES strings, one does not contain stereochemistry\n",
    "    new_ids = largest_cages['bb'].apply(lambda x: x.replace('O=Cc1ccc(/C=C/c2cc(/C=C/c3ccc(C=O)cc3)cc(/C=C/c3ccc(C=O)cc3)c2)cc1', 'O=Cc1ccc(C=Cc2cc(C=Cc3ccc(C=O)cc3)cc(C=Cc3ccc(C=O)cc3)c2)cc1')).to_list()\n",
    "    largest_cages['bb'] = new_ids\n",
    "    largest_cages = largest_cages.drop_duplicates('bb')\n",
    "    print(f\"There are {len(largest_cages)} with cavity diameter of larger than 16 Å\")\n",
    "    return largest_cages\n",
    "get_largest_cages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA_Project_Clean",
   "language": "python",
   "name": "saprojectclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
