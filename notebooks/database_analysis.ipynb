{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Analysis Code\n",
    "\n",
    "Contains code to analyse the training set dataset used for the MPScore. This includes: identifying the functional groups present in the training database; an analysis of the consistency between chemists and the correlation between the SAScore, SCScore and chemist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from rdkit.Chem import AllChem as rdkit\n",
    "import csv\n",
    "from rdkit.Chem.MolStandardize import standardize_smiles\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as it\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances_argmin_min\n",
    "from functools import cache\n",
    "import stk\n",
    "import py3Dmol\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define synthetic accessibility scorers\n",
    "from rdkit.Chem import RDConfig\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n",
    "main_dir = Path(\"..\").resolve()\n",
    "sys.path.append(str(main_dir))\n",
    "\n",
    "import sascorer as sascore\n",
    "sascorer = lambda x: sascore.calculateScore(cached_smiles_converter(x))\n",
    "from utilities.scscore.standalone_model_numpy import SCScorer\n",
    "scscore = SCScorer()\n",
    "scscore.restore()\n",
    "scscorer = cache(scscore.get_score_from_smi)\n",
    "\n",
    "\n",
    "# Load MPScore\n",
    "from scripts.mpscore import MPScore\n",
    "mpscore_path = Path(\"../models/mpscore_calibrated.joblib\").resolve()\n",
    "# Apply global cache to some functions to speed up restarts\n",
    "model = MPScore(param_path=str(Path(\"../scripts/hyperparameters/optimal_params.json\").resolve()))\n",
    "model.restore(str(mpscore_path))\n",
    "model.predict_proba = cache(model.predict_proba)\n",
    "\n",
    "sascore_scaler = lambda x: (x-1)/(10-1)\n",
    "scscore_scaler = lambda x: (x-1)/(5-1)\n",
    "# Create some cached function to speed up repeat computation\n",
    "cached_smiles_converter = lambda x: rdkit.AddHs(rdkit.MolFromSmiles(x))\n",
    "cached_smiles_converter = cache(cached_smiles_converter)\n",
    "cached_standardize_smiles = cache(standardize_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analysing the functional groups in the training dataset\n",
    "def find_functional_groups():\n",
    "    training_db = \"../data/training_mols.json\"\n",
    "    with open(training_db, \"r\") as f:\n",
    "        training_db = json.load(f)\n",
    "    fg_smarts = {\n",
    "        'amine': ('[N]([H])[H]'),\n",
    "        'aldehyde': ('[C](=[O])[H]'),\n",
    "        'carboxylic_acid': ('[C](=[O])-[O][H]'),\n",
    "        'fluorine': ('[F]'),\n",
    "        'chlorine': ('[Cl]'),\n",
    "        'bromine': ('[Br]'),\n",
    "        'iodine': ('[I]'),\n",
    "        'astatine': ('[As]'),\n",
    "        'alcohol': ('[C]([H])([H])-[O][H]'),\n",
    "        'alcohol2': ('[O][H]'),\n",
    "        'alkene': ('[C]=[C]([H])[H]'),\n",
    "        'alkyne': ('[C]#[C][H]'),\n",
    "        'thiol': ('[S][H]'),\n",
    "        'amide': ('[C](=[O])[N]([H])[H]'),\n",
    "        'boronic_acid': ('[B]([O][H])[O][H]'),\n",
    "        'xenon': ('[Xe]'),\n",
    "        'methyl': ('[C]([H])([H])[H]'),\n",
    "        'ethyl': ('[C]([H])([H])[C]([H])([H])[H]'),\n",
    "        'propyl': ('[C]([H])([H])[C]([H])([H])[C]([H])([H])[H]'),\n",
    "    }\n",
    "    fg_counter = defaultdict(int)\n",
    "    removed = []\n",
    "    for inchi in tqdm(training_db):\n",
    "        mol = Chem.AddHs(Chem.MolFromInchi(inchi))\n",
    "        for fg in fg_smarts:\n",
    "            fg_smart = fg_smarts[fg]\n",
    "            counter = 0\n",
    "            substruct = Chem.MolFromSmarts(fg_smart)\n",
    "            matches = mol.GetSubstructMatches(substruct)\n",
    "            counter += len(matches)\n",
    "            # Ignore molecules if functional groups are less than two.\n",
    "            if counter >= 2:\n",
    "                fg_counter[f'{fg}_{counter}'] += 1\n",
    "                removed.append(inchi)\n",
    "                break\n",
    "    sorted_db_funcs = sorted(fg_counter.items(), key=lambda x: x[0])\n",
    "    db_funcs = pd.DataFrame(sorted_db_funcs)\n",
    "    return db_funcs\n",
    "db_fgs = find_functional_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing chemist scores\n",
    "def load_chemist_data():\n",
    "    main_dir = Path('..').resolve()\n",
    "    p1 = main_dir.joinpath(\"data/chemist_data/opinions_becky.json\")\n",
    "    p2 = main_dir.joinpath(\"data/chemist_data/opinions_mebriggs.json\")\n",
    "    p3 = main_dir.joinpath(\"data/chemist_data/filip.csv\")\n",
    "    # Finding disagreements in training data\n",
    "    with open(str(p1)) as f:\n",
    "        rg = json.load(f)\n",
    "    with open(str(p2)) as f:\n",
    "        mb = json.load(f)\n",
    "    with open(str(p3)) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        fs = {rdkit.MolToInchi(rdkit.MolFromSmiles(smi)): sco for sco, smi in reader}\n",
    "    def parse_training(training_dict):\n",
    "        d = defaultdict(list)\n",
    "        for inchi in training_dict:\n",
    "            # Convert and standardise SMILES string.\n",
    "            d['smiles'].append(standardize_smiles(rdkit.MolToSmiles(rdkit.MolFromInchi(inchi))))\n",
    "            d['chemist_score'].append(int(training_dict[inchi]))\n",
    "        return pd.DataFrame(d)\n",
    "    fs = parse_training(fs)\n",
    "    rg = parse_training(rg)\n",
    "    mb = parse_training(mb)\n",
    "    # Molecules scored by all three chemists\n",
    "    all_three = rg.rename(columns={'chemist_score': 'RLG'}).merge(fs.rename(columns={'chemist_score': 'FS'}), on='smiles').merge(mb.rename(columns={'chemist_score': 'MB'}), on='smiles')\n",
    "    # Molecules scored by two chemists\n",
    "    two = pd.concat([rg.merge(fs, on='smiles'), fs.merge(mb, on='smiles'), rg.merge(mb, on='smiles')])\n",
    "    mols = [] \n",
    "    rows = []\n",
    "    count = 0\n",
    "    for i, r in all_three.iterrows():\n",
    "        if (int(r.RLG) != int(r.FS)) or (int(r.FS) != int(r.MB)):\n",
    "            count+=1\n",
    "            rows.append(r)\n",
    "            mols.append(r.smiles)\n",
    "    print(f\"There were {len(all_three)} molecules labelled by all three chemists\")\n",
    "    print(f\"{count} molecules were labelled the same by all three chemists and {len(all_three)-count} were labelled differently.\")\n",
    "    count = 0\n",
    "    column_names = ['RLG', 'FS', 'MB']\n",
    "    df1 = rg.merge(fs, on='smiles')\n",
    "    df1[~df1['smiles'].isin(all_three['smiles'])]\n",
    "    df2 = rg.merge(mb, on='smiles')\n",
    "    df2[~df2['smiles'].isin(all_three['smiles'])]\n",
    "    df3 = fs.merge(mb, on='smiles')\n",
    "    df3[~df3['smiles'].isin(all_three['smiles'])]\n",
    "    for r in pd.concat([df1, df2, df3]).itertuples():\n",
    "        if (int(r.chemist_score_x) == int(r.chemist_score_y)):\n",
    "            count+=1\n",
    "    print(f'There were {count} molecules labelled the same out of those scored by two chemists.')\n",
    "    print(f'There were {len(pd.concat([df1, df2, df3])) - count} molecules labelled differently out of those scored by two chemists.')\n",
    "    print(f'RLG labelled {sum(rg.chemist_score)} easy-to-synthesise and {len(rg)-sum(rg.chemist_score)} difficult-to-synthesise')\n",
    "    print(f'FS labelled {sum(fs.chemist_score)} easy-to-synthesise and {len(fs)-sum(fs.chemist_score)} difficult-to-synthesise')\n",
    "    print(f'MB labelled {sum(mb.chemist_score)} easy-to-synthesise and {len(mb)-sum(mb.chemist_score)} difficult-to-synthesise')\n",
    "    chemist_data = pd.concat([fs, mb, rg])\n",
    "    return chemist_data\n",
    "chemist_data = load_chemist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between the SAScore and SCScore\n",
    "def plot_figure4(recalculate_scores=False):\n",
    "    df_training = pd.read_csv(main_dir.joinpath('data/training_database.csv'))\n",
    "    if recalculate_scores:\n",
    "        df_training['sas'] = [sascorer(m) for m in tqdm(df_training['smiles'], desc=\"Calculating SAScores\")]\n",
    "        df_training['scs'] = [scscorer(m)[1] for m in tqdm(df_training['smiles'], desc=\"Calculating SCScores\")]\n",
    "    # Scaling scores between 0 and 1\n",
    "    df_training['sas_norm'] = [(val-1)/(10-1) for val in df_training['sas'].to_list()]\n",
    "    df_training['scs_norm'] = [(val-1)/(5-1) for val in df_training['scs'].to_list()]\n",
    "    # Plotting SA-SCScore correlations.\n",
    "    print(f\"The correlation between the SAScore and SCScore is: {df_training['scs'].corr(df_training['sas'])}\")\n",
    "    sns.set_style('white')\n",
    "    palette = sns.color_palette() \n",
    "    # Green = palette[2] = Easy-to-synthesise\n",
    "    # Red = palette[3] = Difficult-to-synthesise \n",
    "    colors = [palette[3]] + [palette[2]]\n",
    "    g = sns.jointplot(\n",
    "        data=df_training,\n",
    "        x='sas_norm',\n",
    "        y='scs_norm',\n",
    "        hue='chemist_score',\n",
    "        palette=colors,\n",
    "        space=0.3,\n",
    "        xlim=[0,1.1],\n",
    "        ylim=[0,1.1],\n",
    "        s=2.7,\n",
    "        linewidth=0.2,\n",
    "        height=3.3\n",
    "    )\n",
    "    g.set_axis_labels(xlabel='SAScore', ylabel='SCScore', fontsize='medium')\n",
    "    g.ax_joint.legend_.remove()\n",
    "    g.ax_joint.tick_params('both', labelsize='medium')\n",
    "    return g\n",
    "fig4 = plot_figure4(recalculate_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating SpearmanR on the training set of molecules\n",
    "def calculate_spearman_r(recalculate_scores=False):\n",
    "    df_training = pd.read_csv(main_dir.joinpath('data/training_database.csv'))\n",
    "    if recalculate_scores:\n",
    "        df_training['sas'] = [sascorer(m) for m in tqdm(df_training['smiles'], desc=\"Calculating SAScores\")]\n",
    "        df_training['scs'] = [scscorer(m)[1] for m in tqdm(df_training['smiles'], desc=\"Calculating SCScores\")]\n",
    "        df_training['mpscore'] = [model.predict_proba(cached_smiles_converter(m)) for m in tqdm(df_training['smiles'], desc=\"Calculating MPScores\")]\n",
    "    df_training['sas_norm'] = [(val-1)/(10-1) for val in df_training['sas'].to_list()]\n",
    "    df_training['scs_norm'] = [(val-1)/(5-1) for val in df_training['scs'].to_list()]\n",
    "    r_mp_sc = spearmanr(df_training['scs_norm'], df_training['mpscore'])\n",
    "    r_mp_sa = spearmanr(df_training['sas_norm'], df_training['mpscore'])\n",
    "    r_sa_sc = spearmanr(df_training['sas_norm'], df_training['scs_norm'])\n",
    "    print(f'SpearmanR MP SC {r_mp_sc}')\n",
    "    print(f'SpearmanR MP SA {r_mp_sa}')\n",
    "    print(f'SpearmanR SA SC {r_sa_sc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spearman_r(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Most Similar/Different Molecules\n",
    "\n",
    "The following functions contain code used to identify the most similar and different molecules from the SAScore, SCScore and MPScore. This finds the scores with the largest residual error from the line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_residuals(x, y):\n",
    "    eq = np.polyfit(x=x, y=y, deg=1)\n",
    "    def calc_residual(eq, y_true, x):\n",
    "        linear_func = lambda x: eq[0]*x+eq[1]\n",
    "        y_pred = linear_func(x)\n",
    "        residual = abs(y_true - y_pred)\n",
    "        return residual\n",
    "    residuals = [calc_residual(eq, i, j) for i,j in zip(x, y)]\n",
    "    residuals_sorted = sorted(set(residuals), reverse=True)\n",
    "    five_largest = [residuals.index(i) for i in residuals_sorted[0:3]]\n",
    "    return five_largest\n",
    "\n",
    "\n",
    "def find_smallest_residuals(x, y):\n",
    "    eq = np.polyfit(x=x, y=y, deg=1)\n",
    "    def calc_residual(eq, y_true, x):\n",
    "        linear_func = lambda x: eq[0]*x+eq[1]\n",
    "        y_pred = linear_func(x)\n",
    "        residual = abs(y_true - y_pred)\n",
    "        return residual\n",
    "    residuals = [calc_residual(eq, i, j) for i,j in zip(x, y)]\n",
    "    residuals_sorted = sorted(set(residuals), reverse=False)\n",
    "    largest = [residuals.index(i) for i in residuals_sorted[0:3]]\n",
    "    return largest\n",
    "\n",
    "def find_most_different(df_training):\n",
    "    scores = ['sas_norm', 'scs_norm', 'mpscore']\n",
    "    scores_perms = list(it.combinations(scores, 2))\n",
    "    rows = []\n",
    "    for score_comb in scores_perms:\n",
    "        x, y = df_training[score_comb[0]], df_training[score_comb[1]]\n",
    "        largest = find_largest_residuals(x, y)\n",
    "        smallest = find_smallest_residuals(x, y)\n",
    "        for row_id in largest:\n",
    "            df_row = df_training.iloc[row_id]\n",
    "            df_row = df_row.append(pd.Series({\"score_name\": str(score_comb)+\"_largest\"}))\n",
    "            rows.append(df_row)\n",
    "        for row_id in smallest:\n",
    "            df_row = df_training.iloc[row_id]\n",
    "            df_row = df_row.append(pd.Series({\"score_name\": str(score_comb)+\"_smallest\"}))\n",
    "            rows.append(df_row)\n",
    "    return pd.DataFrame(rows)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation\n",
    "\n",
    "In this section, we identifty the best parameters for the random forest model using a grid search hyperparameter tuning process. \n",
    "The code that runs this tuning process can be found in this [file](../scripts/hyperparam_opt.py) and the screened parameters are in this `JSON` [file](../scripts/hyperparameters/test_params.json).\n",
    "The results of the parameter screening are also provided in a JSON format [here]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(n_params=5, db_path=None):\n",
    "    if db_path:\n",
    "        data = pd.read_json(db_path)\n",
    "    else:\n",
    "        client = MongoClient(\"129.31.65.124\")\n",
    "        collection = client[\"sa_project\"][\"hyperparameters\"]\n",
    "        data = pd.DataFrame(list(collection.find()))\n",
    "    best_n = data.query(\"run_id == 'Top_5_Run_2'\").sort_values(by='FBeta (Beta = 2/10)', ascending=False).iloc[0:n_params]\n",
    "    best_n.dropna(axis=1, inplace=True, how='all')\n",
    "    return best_n\n",
    "best_params = get_best_parameters(n_params=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Precursor Screening\n",
    "\n",
    "In this section, we filter for easy-to-synthesise molecules using our developed MPScore, the SAScore and SCScore.\n",
    "We show the distriubtions of synthetic difficulty scores for each precursor combination in our precursor database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure6(model, standardize_smiles, cached_smiles_converter, recalculate_scores):\n",
    "    df_combinations = get_precursor_combinations(model=model, standardize_smiles=standardize_smiles, cached_smiles_converter=cached_smiles_converter, recalculate_scores=recalculate_scores)\n",
    "    sns.set_style('white')\n",
    "    palette = sns.color_palette()\n",
    "    fig, ax = plt.subplots(1, figsize=(6.43420506434205/2, 3.1))\n",
    "    sns.kdeplot(data=df_combinations, x='sascore_combination', ax=ax, color=palette[0])\n",
    "    sns.kdeplot(data=df_combinations, x='scscore_combination', ax=ax, color=palette[1])\n",
    "    sns.kdeplot(data=df_combinations, x='mpscore_combination', ax=ax, color=palette[3])\n",
    "    sns.despine()\n",
    "    ax.set_xlabel('Synthetic Difficulty', fontsize='medium')\n",
    "    ax.set_ylabel('Density', fontsize='medium')\n",
    "    ax.axvline(df_combinations['sascore_combination'].quantile(0.01), 0, 0.7, color=palette[0], linestyle =\"--\")\n",
    "    ax.text(df_combinations['sascore_combination'].quantile(0.01)-0.03, 3.7, f\"{round(df_combinations['sascore_combination'].quantile(0.01), 2)}\", color=palette[0], fontsize=8)\n",
    "    ax.text(df_combinations['sascore_combination'].quantile(0.01)-0.07, 4, \"SAScore\", color=palette[0], fontsize=8)\n",
    "\n",
    "    ax.axvline(df_combinations['scscore_combination'].quantile(0.01), 0, 0.7, color=palette[1], linestyle =\"--\")\n",
    "    ax.text(0.05, 3.7, f\"{round(df_combinations['scscore_combination'].quantile(0.01), 2)}\", color=palette[1], fontsize=8)\n",
    "    ax.text(0, 4, \"SCScore\", color=palette[1], fontsize=8)\n",
    "\n",
    "    ax.axvline(df_combinations['mpscore_combination'].quantile(0.01), 0, 0.7, color=palette[3], linestyle =\"--\")\n",
    "    ax.text(0.25, 3.7, f\"{round(df_combinations['mpscore_combination'].quantile(0.01), 2)}\", color=palette[3], fontsize=8)\n",
    "    ax.text(0.2, 4, \"MPScore\", color=palette[3], fontsize=8)\n",
    "\n",
    "    ax.tick_params(labelsize='medium')\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precursor_combinations(model, standardize_smiles, cached_smiles_converter, recalculate_scores=True):\n",
    "    # Loading Reaxys data\n",
    "    df_reaxys = pd.read_csv(\"../data/reaxys_database.csv\")\n",
    "    if recalculate_scores:\n",
    "        df_reaxys['sas'] = [sascorer(m) for m in tqdm(df_reaxys['smiles'], desc=\"Calculating SAScores\")]\n",
    "        df_reaxys['scs'] = [scscorer(m)[1] for m in tqdm(df_reaxys['smiles'], desc=\"Calculating SCScores\")]\n",
    "        df_reaxys['mpscore'] = [model.predict_proba(cached_smiles_converter(m)) for m in tqdm(df_reaxys['smiles'], desc=\"Calculating MPScore:\")]\n",
    "        df_reaxys['sas_norm'] = [sascore_scaler(i) for i in df_reaxys['sas']]\n",
    "        df_reaxys['scs_norm'] = [scscore_scaler(i) for i in df_reaxys['scs']]\n",
    "    bb_gen = it.product(\n",
    "        (r[1] for r in df_reaxys[df_reaxys[\"func_group\"] == \"primary amine\"].iterrows()),\n",
    "        (r[1] for r in df_reaxys[df_reaxys[\"func_group\"] == \"aldehyde\"].iterrows()),\n",
    "    )\n",
    "    combinations = defaultdict(list)\n",
    "    ncombinations = len(df_reaxys[df_reaxys[\"func_group\"] == \"primary amine\"])*len(df_reaxys[df_reaxys[\"func_group\"] == \"aldehyde\"])\n",
    "    for bbs in tqdm(bb_gen, total=ncombinations):\n",
    "        amine_smiles, aldehyde_smiles = bbs[0]['smiles'], bbs[1]['smiles'] \n",
    "        combinations[\"_id\"].append(\n",
    "            aldehyde_smiles + ',' + amine_smiles\n",
    "        )\n",
    "        combinations[\"sascore_combination\"].append(sum(r[\"sas_norm\"] for r in bbs)/2)\n",
    "        combinations[\"scscore_combination\"].append(sum(r[\"scs_norm\"] for r in bbs)/2)\n",
    "        combinations[\"mpscore_combination\"].append(sum(r[\"mpscore\"] for r in bbs)/2)\n",
    "    return pd.DataFrame(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combinations = get_precursor_combinations(model=model, standardize_smiles=standardize_smiles, cached_smiles_converter=cached_smiles_converter, recalculate_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_7(model, standardize_smiles, cached_smiles_converter, recalculate_scores=True):\n",
    "    df_combinations = get_precursor_combinations(model=model, standardize_smiles=standardize_smiles, cached_smiles_converter=cached_smiles_converter, recalculate_scores=recalculate_scores)\n",
    "    # Loading optimised cages\n",
    "    df = pd.read_json('../data/all_optimised.json').drop_duplicates('_id')\n",
    "    df_random_selection = pd.read_json('../data/control.json').drop_duplicates('_id')\n",
    "    # Selecting first percentile of synthetic accessibility scores for the MPScore.\n",
    "    mpscore_selected = df_combinations[df_combinations['mpscore_combination'] < df_combinations['mpscore_combination'].quantile(0.01)].drop_duplicates('_id')['_id']\n",
    "    sa_selected = df_combinations[df_combinations['sascore_combination'] < df_combinations['sascore_combination'].quantile(0.01)].drop_duplicates('_id')['_id']\n",
    "    sc_selected = df_combinations[df_combinations['scscore_combination'] < df_combinations['scscore_combination'].quantile(0.01)].drop_duplicates('_id')['_id']\n",
    "    mpscore_cages = df[df['_id'].isin(mpscore_selected)].merge(df_combinations, how='left', on='_id').drop_duplicates('_id')\n",
    "    sa_cages = df[df['_id'].isin(sa_selected)].merge(df_combinations, how='left', on='_id').drop_duplicates('_id')\n",
    "    sc_cages = df[df['_id'].isin(sc_selected)].merge(df_combinations, how='left', on='_id').drop_duplicates('_id')\n",
    "    assert all((len(mpscore_cages) == len(mpscore_selected), len(sc_cages) == len(sc_selected), len(sa_cages) == len(sa_selected)))\n",
    "    sp_sc_cages = sc_cages[(sc_cages['collapsed'] == False) & (sc_cages['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    sp_mpscore_cages = mpscore_cages[(mpscore_cages['collapsed'] == False) & (mpscore_cages['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    sp_sa_cages = sa_cages[(sa_cages['collapsed'] == False) & (sa_cages['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    sp_random = df_random_selection[(df_random_selection['collapsed'] == False) &  (df_random_selection['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    print(f\"Mean of SCScore selected cages: {sp_sc_cages['cavity_size'].mean()}\")\n",
    "    print(f\"Mean of SAScore selected cages: {sp_sa_cages['cavity_size'].mean()}\")\n",
    "    print(f\"Mean of MPScore selected cages: {sp_mpscore_cages['cavity_size'].mean()}\")\n",
    "    print(f\"Mean of randomly selected cages: {sp_random['cavity_size'].mean()}\")\n",
    "    print(\n",
    "        f\"Number of shape persistent from SCScore: {len(sp_sc_cages)}\\n\"\n",
    "        f\"Number of shape persistent from SAScore: {len(sp_sa_cages)}\\n\"\n",
    "        f\"Number of shape persistent from MPScore: {len(sp_mpscore_cages)}\\n\"\n",
    "        f\"Number of shape persistent from control sample: {len(sp_random)}\\n\"\n",
    "    )\n",
    "    palette = sns.color_palette()\n",
    "    colors = {\n",
    "        'sascore': palette[0],\n",
    "        'scscore': palette[1],\n",
    "        'mpscore': palette[3]\n",
    "    }\n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(figsize=(6.43420506434205/2, 3.3))\n",
    "    mpscore_cavity_sizes = sp_mpscore_cages['cavity_size']\n",
    "    sns.histplot(x=mpscore_cavity_sizes, ax=ax, kde=False, color=colors['mpscore'], element='step', edgecolor=colors['mpscore'], linewidth=1, alpha=0.4, label='MPScore')\n",
    "    sa_cavity_sizes =sp_sa_cages['cavity_size']\n",
    "    random_cavity_sizes = df_random_selection[(df_random_selection['collapsed'] == False) &  (df_random_selection['cavity_size'] > 1.0)]['cavity_size']\n",
    "    sns.histplot(x=random_cavity_sizes, ax=ax, kde=False, color='green', element='step', edgecolor='green', linewidth=1, alpha=0.4, label='Control Sample')\n",
    "    sc_cavity_sizes = sp_sc_cages['cavity_size']\n",
    "    sns.histplot(x=sc_cavity_sizes, ax=ax, kde=False, color=colors['scscore'], element='step', edgecolor=colors['scscore'], linewidth=1, alpha=0.4, label='SCScore')\n",
    "    sns.histplot(x=sa_cavity_sizes, ax=ax , kde=False, color=colors['sascore'], element='step', edgecolor=colors['sascore'], linewidth=1, alpha=0.4, label='SAScore')\n",
    "    ax.set_xlim(0, 20)\n",
    "    ax.set_xlabel('Cavity Diameter / Å', fontsize='medium')\n",
    "    ax.set_ylabel('Number of Cages', fontsize='medium')\n",
    "    sns.despine()\n",
    "    ax.tick_params(labelsize='medium')\n",
    "    ax.legend(fontsize=\"small\")\n",
    "    return fig\n",
    "fig7 = plot_figure_7(model=model, standardize_smiles=standardize_smiles, cached_smiles_converter=cached_smiles_converter, recalculate_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_largest_cages():\n",
    "    df_combinations = get_precursor_combinations(model=model, standardize_smiles=standardize_smiles, cached_smiles_converter=cached_smiles_converter, recalculate_scores=True)\n",
    "    # Loading optimised cages\n",
    "    df = pd.read_json('../data/all_optimised.json').drop_duplicates('_id')\n",
    "    # Selecting first percentile of synthetic accessibility scores for the MPScore.\n",
    "    mpscore_selected = df_combinations[df_combinations['mpscore_combination'] < df_combinations['mpscore_combination'].quantile(0.01)].drop_duplicates('_id')['_id']\n",
    "    sa_selected = df_combinations[df_combinations['sascore_combination'] < df_combinations['sascore_combination'].quantile(0.01)].drop_duplicates('_id')['_id']\n",
    "    sc_selected = df_combinations[df_combinations['scscore_combination'] < df_combinations['scscore_combination'].quantile(0.01)].drop_duplicates('_id')['_id']\n",
    "    mpscore_cages = df[df['_id'].isin(mpscore_selected)].merge(df_combinations, how='left', on='_id').drop_duplicates('_id')\n",
    "    sa_cages = df[df['_id'].isin(sa_selected)].merge(df_combinations, how='left', on='_id').drop_duplicates('_id')\n",
    "    sc_cages = df[df['_id'].isin(sc_selected)].merge(df_combinations, how='left', on='_id').drop_duplicates('_id')\n",
    "    assert all((len(mpscore_cages) == len(mpscore_selected), len(sc_cages) == len(sc_selected), len(sa_cages) == len(sa_selected)))\n",
    "    sp_sc_cages = sc_cages[(sc_cages['collapsed'] == False) & (sc_cages['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    sp_mpscore_cages = mpscore_cages[(mpscore_cages['collapsed'] == False) & (mpscore_cages['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    sp_sa_cages = sa_cages[(sa_cages['collapsed'] == False) & (sa_cages['cavity_size'] > 1.0)].drop_duplicates('_id')\n",
    "    \n",
    "    largest_cages = pd.concat([sp_mpscore_cages, sp_sa_cages, sp_sc_cages])\n",
    "    print('Selecting cages with cavity size > 16 Å')\n",
    "    largest_cages = largest_cages.query('cavity_size >= 16.0')\n",
    "    # Used to replace SMILES strings, one does not contain stereochemistry\n",
    "    new_ids = largest_cages['_id'].apply(lambda x: x.replace('O=Cc1ccc(/C=C/c2cc(/C=C/c3ccc(C=O)cc3)cc(/C=C/c3ccc(C=O)cc3)c2)cc1', 'O=Cc1ccc(C=Cc2cc(C=Cc3ccc(C=O)cc3)cc(C=Cc3ccc(C=O)cc3)c2)cc1')).to_list()\n",
    "    largest_cages['_id'] = new_ids\n",
    "    largest_cages = largest_cages.drop_duplicates('_id')\n",
    "    print(f\"There are {len(sp_sa_cages.drop_duplicates('_id'))} shape-persistent cages form the SAScore\")\n",
    "    print(f\"There are {len(sp_sc_cages.drop_duplicates('_id'))} shape-persistent cages form the SCScore\")\n",
    "    print(f\"There are {len(sp_mpscore_cages.drop_duplicates('_id'))} shape-persistent cages form the MPScore\")\n",
    "    print(f\"There are {len(sp_sa_cages.query('cavity_size > 16'))} from the SAScore\")\n",
    "    print(f\"There are {len(sp_sc_cages.query('cavity_size > 16'))} from the SCScore\")\n",
    "    print(f\"There are {len(sp_mpscore_cages.query('cavity_size > 16'))} from the MPScore\")\n",
    "    return largest_cages\n",
    "largest_cages = get_largest_cages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Molecules with Similar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_molecules(chemist_data):\n",
    "    e2s = chemist_data.query('chemist_score == 1')\n",
    "    d2s = chemist_data.query('chemist_score == 0')\n",
    "    e2s_fps = [rdkit.GetMorganFingerprintAsBitVect(rdkit.MolFromSmiles(m), nBits=1024, radius=3) for m in e2s['smiles']]\n",
    "    d2s_fps = [rdkit.GetMorganFingerprintAsBitVect(rdkit.MolFromSmiles(m), nBits=1024, radius=3) for m in d2s['smiles']]\n",
    "    pca1 = PCA(n_components=50, random_state=32)\n",
    "    e2s_components = pca1.fit_transform(e2s_fps)\n",
    "    print(f\"For easy-to-synthesise, PCA capture {np.sum(pca1.explained_variance_ratio_)*100}% of the variance\")\n",
    "    pca2 = PCA(n_components=50, random_state=32)\n",
    "    d2s_components = pca2.fit_transform(d2s_fps)\n",
    "    print(f\"For difficult-to-synthesise, PCA capture {np.sum(pca2.explained_variance_ratio_)*100}% of the variance\")\n",
    "    def find_best_sil(X):\n",
    "        sil = {}\n",
    "        intertias = []\n",
    "        for i in range(2, 11, 1):\n",
    "            kmeans = KMeans(n_clusters=i, random_state=32, n_init=50)\n",
    "            kmeans.fit(X)\n",
    "            intertias.append(kmeans.inertia_)\n",
    "            sil[i] = silhouette_score(X, kmeans.labels_)\n",
    "            print(f\"Intertia for {i} clusters is {kmeans.inertia_}. Silhouette score is {sil[i]}\")\n",
    "\n",
    "\n",
    "        max_sil = max(sil.items(), key=lambda x: x[1])\n",
    "        best_cluster = max_sil[0]\n",
    "        print(f\"The best performing cluster is {best_cluster} with a score of {max_sil[1]}\")\n",
    "        return best_cluster\n",
    "    \n",
    "    def find_closest_cluster(clusters, X_transformed):\n",
    "        kmeans = KMeans(n_clusters=clusters, random_state=32)\n",
    "        kmeans.fit(X_transformed)\n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X_transformed)\n",
    "        return closest\n",
    "        \n",
    "\n",
    "    e2s_nclusters = find_best_sil(e2s_components)\n",
    "    d2s_nclusters = find_best_sil(d2s_components)\n",
    "    e2s_closest_idx = find_closest_cluster(clusters=10, X_transformed=e2s_components)\n",
    "    e2s_closest_mols = [rdkit.MolFromSmiles(m) for m in e2s['smiles'].iloc[e2s_closest_idx]]\n",
    "    d2s_closest_idx = find_closest_cluster(clusters=10, X_transformed=d2s_components)\n",
    "    d2s_closest_mols = [rdkit.MolFromSmiles(m) for m in d2s['smiles'].iloc[d2s_closest_idx]]\n",
    "    return e2s_closest_mols, d2s_closest_mols\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA_Project_Clean",
   "language": "python",
   "name": "saprojectclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
